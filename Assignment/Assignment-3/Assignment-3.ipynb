{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1615280e",
   "metadata": {},
   "source": [
    "# NLP Assignment 3\n",
    "1. What's the difference between regular grammar and regular expressions?\n",
    "2. In the context of NLP, what is parsing?\n",
    "3. What exactly is the TF-IDF procedure?\n",
    "4. Which factors influence Natural Language Processing interpretation?\n",
    "5. What are the different types of conversational interfaces?\n",
    "6. Apply Uni-gram and Bi-grammar-gram to the statement \"I am really happy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be524ee",
   "metadata": {},
   "source": [
    "## 1. What's the difference between regular grammar and regular expressions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb5d76",
   "metadata": {},
   "source": [
    "   - There is a concept of regular language in theory of computation. Regular language is language which is accepted by finite automaton. Here finite automaton is a machine which checks whether the language is regular or not. If given language is accepted by machine then the language is regular. If not then language is not regular.\n",
    "\n",
    "        E.g. : compiler, it checks given source code and if any error is present in code it shows that error.\n",
    "        \n",
    "   - Regular expressions, regular grammars and finite automata are simply three different formalisms for the same thing. There are algorithms to convert from any of them to any other.\n",
    "    Now,\n",
    "\n",
    "#### Regular grammar: \n",
    "   - It is a generator of regular language. A language which should generate all the strings from given language is called generator. For generating regular language we need some rules and that are defined in grammar. Grammar is embedded in compiler to check given source code.\n",
    "   \n",
    "- Regular grammars consist of a four tuple (N,Σ,P,S∈N) where N is the set of non-terminals, Σ is the set of terminals, S is the start non-terminal and P is the set of productions which tell us how to change the start symbol, step by step, into a string in Σ∗. P can have its productions drawn from one of two types (not both though):\n",
    "\n",
    "1. Right Linear Grammars:\n",
    "\n",
    "- For non-terminals B, C, terminal a and the empty string ε, all rules are of the form:\n",
    "    - B→a\n",
    "    - B→aC\n",
    "    - B→ε\n",
    "    \n",
    "2. Left Linear Grammars:\n",
    "\n",
    "Left linear grammars are the same, but rule #2 is B→Ca.\n",
    "\n",
    "####  Regular expression: \n",
    "- It is representator of regular language. Regular expression is mathematically represent by some expression called regular expression. Regular expression is character sequence that define a search pattern.\n",
    "\n",
    "- So regular expressions are recursively defined as follows:\n",
    "    - ∅ is a regular expression\n",
    "    - ε is a regular expression\n",
    "    - a is a regular expression for every a∈Σ\n",
    "    - if A and B are regular expressions then\n",
    "    - A⋅B is a regular expression (concatentation)\n",
    "    - A∣B is a regular expression (alternation)\n",
    "    - A∗ is a regular expression (Kleene star)\n",
    "    Along with some semantics (i.e. how we interpret the operators to get a string), we get a way of generating strings from a regular language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf37d22",
   "metadata": {},
   "source": [
    "## 2. In the context of NLP, what is parsing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0373928",
   "metadata": {},
   "source": [
    "- A-Parser may be defined as a software component that takes text as input and converts it into a structural representation after verifying for correct syntax using formal grammar. It also creates a data structure, which can be a parse tree, an abstract syntax tree, or another hierarchical structure.\n",
    "- The third phase of NLP is syntactic analysis, sometimes known as parsing or syntax analysis.\n",
    "- The goal of this step is to extract precise, or dictionary-like, meaning from the text.\n",
    "- Syntax analysis compares the text to formal grammar rules to determine its meaning.\n",
    "- Syntactic analysis, often known as parsing, is the process of analyzing strings of symbols in natural language according to formal grammar principles.\n",
    "\n",
    "Parsing is divided into two categories by derivation:\n",
    "- Parsing from the top down - The parser constructs the parse tree from the start symbol and then tries to translate the start symbol to the input in this type of parsing.\n",
    "- Parsing from the bottom up - The parser starts with the input symbol and tries to build the parser tree up to the start symbol in this type of parsing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b0f19f",
   "metadata": {},
   "source": [
    "## 3. What exactly is the TF-IDF procedure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b945f",
   "metadata": {},
   "source": [
    "- TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents.\n",
    "\n",
    "- This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbdc409",
   "metadata": {
    "colab_type": "text",
    "id": "w9n624C3yuML"
   },
   "source": [
    "### Sklearn implements TF-IDF algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a9233e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GfNfRBSyuMM",
    "outputId": "92169ae9-418e-45d1-b05a-99cc1266b71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output x_train text vector：\n",
      "[[0.22941573 0.22941573 0.22941573 0.45883147 0.22941573 0.22941573\n",
      "  0.22941573 0.22941573 0.45883147 0.45883147]]\n",
      "Output x_test text vector：\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "x_train = ['The main idea of TF-IDF is that algorithm is an important feature that can be separated from the corpus background']\n",
    "x_test=['Original text marked ',' main idea']\n",
    " \n",
    "vectorizer = CountVectorizer(max_features=10)\n",
    "\n",
    "tf_idf_transformer = TfidfTransformer()\n",
    "\n",
    "tf_idf = tf_idf_transformer.fit_transform(vectorizer.fit_transform(x_train))\n",
    "\n",
    "x_train_weight = tf_idf.toarray()\n",
    " \n",
    "\n",
    "tf_idf = tf_idf_transformer.transform(vectorizer.transform(x_test))\n",
    "x_test_weight = tf_idf.toarray()\n",
    " \n",
    "print('Output x_train text vector：')\n",
    "print(x_train_weight)\n",
    "print('Output x_test text vector：')\n",
    "print(x_test_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39da9a",
   "metadata": {},
   "source": [
    "## 4. Which factors influence Natural Language Processing interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b285a7",
   "metadata": {},
   "source": [
    "- Natural Language Processing is the technique used by computers to understand and take actions based upon human languages such as English. It is a part of Artificial Intelligence and cognitive computing. The process involves speech to text conversion, training the machine for intelligent decision making or actions. \n",
    "\n",
    "- Natural Language Processing or NLP works on the unstructured form of data, and it depends upon several factors such as regional languages, accent, grammar, tone, sentiments, locality, slang, pronunciation, etc.\n",
    "\n",
    "- There are certain steps that NLP uses, such as lexical analysis, syntactical analysis, semantic analysis, discourse integration, and pragmatic analysis. Some of the popular NLP implementations are Amazon Alexa, Google Assistant, and Chatbots.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bf96d",
   "metadata": {},
   "source": [
    "## 5. What are the different types of conversational interfaces?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e242d",
   "metadata": {},
   "source": [
    "- The conversational interface is an interface you can talk/write to in plain language. The aim is to provide a seamless user experience, as if you are talking to a friend or acquaintance. However, in practice, conversational interfaces mostly act as a stop-gap, answering basic questions, but unable to offer as much support as a live agent.\n",
    "\n",
    "\n",
    "    - Basic bots\n",
    "    - Text-based assistants\n",
    "    - Voice assistants\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9b8ea",
   "metadata": {},
   "source": [
    "## 6. Apply Uni-gram and Bi-grammar-gram to the statement \"I am really happy.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537e0aa",
   "metadata": {
    "colab_type": "text",
    "id": "MIKOVLUfyuMa"
   },
   "source": [
    "\n",
    "\n",
    "**In computational linguistics, n-gram refers to n consecutive items in the text (items can be phoneme, syllable, letter, word or base pairs)**\n",
    "\n",
    "N-grams of texts are widely used in the field of text mining and natural language processing. They are basically a set of co-occurring words within a defined window and when computing the n-grams, we typically move one word forward or more depending upon the scenario.\n",
    "\n",
    ">For example, for the sentence **“The cow jumps over the moon”**. If **N=2** (known as bigrams), then the ngrams would be:\n",
    "\n",
    "* the cow\n",
    "* cow jumps\n",
    "* jumps over\n",
    "* over the\n",
    "* the moon\n",
    "\n",
    "In n-gram, **n = 1 is unigram**, **n = 2 is bigram**, **n = 3 is trigram**. \n",
    "\n",
    "gram is often used to compare sentence similarity, fuzzy query, sentence rationality, sentence correction, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b3f04",
   "metadata": {
    "colab_type": "text",
    "id": "U8dpWgzryuMb"
   },
   "source": [
    "### Unigram Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceca8acb",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YLq3kK2yuMc",
    "outputId": "ecfa1476-a33b-415f-94ca-a965f01e71e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'really', 'happy.']\n"
     ]
    }
   ],
   "source": [
    "Sent = \"I am really happy.\"\n",
    "lst_sent = Sent.split (\" \")\n",
    "of_unigrams_in = []\n",
    "for i in range(len(lst_sent)):\n",
    "   of_unigrams_in.append(lst_sent[i])\n",
    "   \n",
    "    \n",
    "print(of_unigrams_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f721ae8",
   "metadata": {
    "colab_type": "text",
    "id": "K-ye2OG2yuMe"
   },
   "source": [
    "### Bigram Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868d3797",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pktQcu1tyuMf",
    "outputId": "7f7072f7-d0a2-4ed3-c608-9adcc9d7974c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I am', 'am really', 'really happy.']\n"
     ]
    }
   ],
   "source": [
    "Sent = \"I am really happy.\"\n",
    "lst_sent = Sent.split (\" \")\n",
    "of_bigrams_in = []\n",
    "for i in range(len(lst_sent)- 1):\n",
    "   of_bigrams_in.append(lst_sent[i]+ \" \" + lst_sent[ i + 1])\n",
    "   \n",
    "    \n",
    "print(of_bigrams_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3acfa98",
   "metadata": {
    "colab_type": "text",
    "id": "cFklgTn9yuMi"
   },
   "source": [
    "### Trigram Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9217ceb",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fo-_ANz0yuMj"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation_pattern = re.compile(r\"\" \"[.,!? \"\"] \"\" \" )\n",
    "\n",
    "sent = \"I am really happy.\"\n",
    "no_punctuation_sent = re.sub(punctuation_pattern , \" \" , sent )\n",
    "lst_sent = no_punctuation_sent.split (\" \")\n",
    "trigram = []\n",
    "for i in range(len(lst_sent)- 2):\n",
    "   trigram.append(lst_sent[i] + \" \" + lst_sent[i + 1] + \" \" +lst_sent[i + 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc58ebda",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKrjCaxTyuMl",
    "outputId": "3d7ac081-a5e8-42b6-a92d-8d487c6a0128",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am really', 'am really happy.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24421a3",
   "metadata": {},
   "source": [
    "**References:**\n",
    "    \n",
    "    - https://cs.stackexchange.com/questions/45755/difference-between-regular-expression-and-grammar-in-automata\n",
    "    - https://www.tutorialspoint.com/natural_language_toolkit/natural_language_toolkit_parsing.htm#:~:text=Parsing%20and%20its%20relevance%20in,Syntactic%20analysis%20or%20syntax%20analysis.\n",
    "    - https://monkeylearn.com/blog/what-is-tf-idf/#:~:text=TF%2DIDF%20(term%20frequency%2D,across%20a%20set%20of%20documents.\n",
    "    - https://www.educba.com/what-is-natural-language-processing/\n",
    "    - https://alan.app/blog/what-is-conversational-user-interface-cui/#TypesofConversationalUserInterfaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
