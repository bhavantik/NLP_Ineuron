{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define Natural Language Processing (NLP).\n",
    "2. What is the acronym for NLP?\n",
    "3. Any four NLP applications should be mentioned.\n",
    "4. Explain the Spacy library in a few words.\n",
    "5. Mention how important NLTK is.\n",
    "6. Mention the NLTK library's libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Natural language processing is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data\" - Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the acronym for NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NLP Stands for Natural Langauge Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Any four NLP applications should be mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Speech Recognition:\n",
    "    - Speech Recognition is a technology that enables the computer to convert voice input data to machine readable format. There are a lot of fields where speech recognition is used like, virtual assistants, adding speech-to-text, translating speech, sending emails etc. \n",
    "    - It is used in search engines where the user can voice out the name of their search requirements and get the desired result, making our work easier than typing out the entire command.\n",
    "    - Examples: Google Assistance, Cortana, Siri, etc.\n",
    "    \n",
    "2. Voice Assistants and Chatbots:\n",
    "- All of us are well versed with the idea of Voice assistants like Alexa, Siri and Google Assistant, and chatbots that are integrated in many websites to help and guide new users. \n",
    "\n",
    " \n",
    "\n",
    "Voice assistant is a software that uses NLP and speech recognition to understand voice commands of a user and perform accordingly. Similarly, Chatbots are programs that are designed to assist an user 24/7 and respond appropriately and answer any query that the user might have.\n",
    "\n",
    " \n",
    "\n",
    "Most Chatbots and Virtual Assistants have pre-programmed answering systems that follow specific rules and patterns while answering. Powerful AI has enabled some voice assistants to interact with the user and respond appropriately. With more usage, they even improve themselves. Assistants like Siri and Alexa can even have a conversation with the user like a normal human being!\n",
    "\n",
    "3. Sentiment Analysis:\n",
    "- Human speech could be quite hard to interpret as it involves expressions and sentiments beyond literal meanings. Expressions like sarcasm, threat, exclamation etc. are often very hard to be recognised by the computer.\n",
    "\n",
    " \n",
    "\n",
    "But, with the help of Natural Language Understanding (NLU) which is a subfield of Natural Language Processing, the machine is able to catch on to different sentiments that might be insisted on through the user’s command.  \n",
    "\n",
    " \n",
    "\n",
    "Through sentiment analysis, one can analyse customer reactions, handle social media disputes by eradicating negative comments and getting insights from the customer base of any business.\n",
    "\n",
    "\n",
    "4. Email Filtering:\n",
    "Most of the professional work is done through emails and it would be quite a hassle if all the emails we received were not segregated into different sections. Gmail classifies all the emails into primary, social and promotional sections. Even all the spam emails are sent to a different section so that they do not flood our inbox. \n",
    "\n",
    " \n",
    "\n",
    "This is done with the help of text classification, which is a technique of NLP.  It has definitely helped us save time and not miss any important Email that might have gotten lost if all the useless emails started accumulating in our inbox.\n",
    "\n",
    "\n",
    "Source: https://www.analyticssteps.com/blogs/top-10-applications-natural-language-processing-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explain the Spacy library in a few words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spaCy (/speɪˈsiː/ spay-SEE) is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.[3][4] The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\n",
    "\n",
    "- Unlike NLTK, which is widely used for teaching and research, spaCy focuses on providing software for production usage.[5][6] spaCy also supports deep learning workflows that allow connecting statistical models trained by popular machine learning libraries like TensorFlow, PyTorch or MXNet through its own machine learning library Thinc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e4ec16f21177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pip install -U spacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# python -m spacy download en_core_web_sm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load English tokenizer, tagger, parser and NER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Mention how important NLTK is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Mention the NLTK library's libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
